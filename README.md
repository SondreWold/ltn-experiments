# Approaching the Super GLUE benchmark with Logic Tensor Networks
Comparing standard CrossEntropy based training on the GLUE tasks to a LTN based approach using the SatAgg objective. 

## Why?

Why not?

## Datasets

## Representing the tasks as First Order Logic

## Comparison with baseline models

## Lessons learned
